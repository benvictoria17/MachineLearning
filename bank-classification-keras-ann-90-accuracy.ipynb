{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T19:02:07.207130Z","iopub.execute_input":"2021-11-28T19:02:07.207721Z","iopub.status.idle":"2021-11-28T19:02:07.224561Z","shell.execute_reply.started":"2021-11-28T19:02:07.207627Z","shell.execute_reply":"2021-11-28T19:02:07.223910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('https://raw.githubusercontent.com/benvictoria17/MachineLearning/master/dataset/Bank%20Marketing/bank.csv')\nX = dataset.iloc[:,0:16].values\ny = dataset.iloc[:,-1].values","metadata":{"execution":{"iopub.status.busy":"2021-11-28T19:02:07.226056Z","iopub.execute_input":"2021-11-28T19:02:07.226371Z","iopub.status.idle":"2021-11-28T19:02:07.502685Z","shell.execute_reply.started":"2021-11-28T19:02:07.226336Z","shell.execute_reply":"2021-11-28T19:02:07.501971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y_1 = LabelEncoder()\n#reshape y\ny = np.reshape(y,(-1,1)) #label encoder requires 2-dim array\ny[:,0] = labelencoder_y_1.fit_transform(y[:, 0]) \n#encoding X\n#first split X into numerical and categorical arrays\nX_numerical = X[:,[0,5,9,11,12,13,14]]\nX_categorical = X[:,[1,2,3,4,6,7,8,10,15]]\n#encoding X_categorical\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\norginalNumOfColsOfX_categorical = X_categorical.shape[1]\nfor i in range(X_categorical.shape[1]): \n    currNumOfColsOfX_categorical = X_categorical.shape[1]\n    indexOfColumnToEncode = currNumOfColsOfX_categorical - orginalNumOfColsOfX_categorical + i\n    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [indexOfColumnToEncode])], remainder='passthrough', sparse_threshold=0)\n    X_categorical = np.array(ct.fit_transform(X_categorical)) \n    X_categorical = X_categorical[:, 1:] #get rid of dummy variable\n    \n#join X_numerical and X_categorical into one array\nX = np.concatenate((X_numerical,X_categorical), axis=1)\n#Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n#Feature Scaling i.e Standardisation or Normalisation\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n#Importing the ANN libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n#After 14 different hyperparameter tunings I found the following to most effective and reduce over-fitting\n# Initialising the ANN\nclassifier = Sequential()\n# Adding first hidden layer\nclassifier.add(Dense(units = 21, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dropout(0.1))\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\ny_test = y_test.astype('float64') #to have the same type as the other sets\ny_train = y_train.astype('float64') #to have the same type as the other sets\nclassifierHistory = classifier.fit(X_train, y_train, batch_size = 64, epochs = 60, validation_data=(X_test,y_test)) ","metadata":{"execution":{"iopub.status.busy":"2021-11-28T19:02:07.504025Z","iopub.execute_input":"2021-11-28T19:02:07.504444Z","iopub.status.idle":"2021-11-28T19:02:36.217066Z","shell.execute_reply.started":"2021-11-28T19:02:07.504407Z","shell.execute_reply":"2021-11-28T19:02:36.216330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_pred = classifier.predict(X_test)\nfor i in range(y_pred.shape[0]):\n    if y_pred[i,0] > 0.5: #using 50% as a threshold - same as sigmoid function used above\n        y_pred[i,0] = 1\n    else:\n        y_pred[i,0] = 0\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n#Evaluating our classification model\nscores = classifier.evaluate(X_test, y_test)\nprint('Accuracy: %.2f%%' % (scores[1]*100))\n#Using our confusion matrix\naccuracy = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[1,1]+cm[0,1]+cm[1,0])\nprint('Confusion matrix accuracy: %.2f%%' % (accuracy*100))\nprecision = cm[0,0]/(cm[0,0]+cm[0,1])\nprint('Confusion matrix precision: %.2f%%' % (precision*100))\nrecall = cm[0,0]/(cm[0,0]+cm[1,0])\nprint('Confusion matrix recall: %.2f%%' % (recall*100))\nf1Score = 2*precision*recall/(precision+recall)\nprint('Confusion matrix f1Score: %.2f%%' % (f1Score*100))","metadata":{"execution":{"iopub.status.busy":"2021-11-28T19:03:16.389698Z","iopub.execute_input":"2021-11-28T19:03:16.389949Z","iopub.status.idle":"2021-11-28T19:03:16.637538Z","shell.execute_reply.started":"2021-11-28T19:03:16.389920Z","shell.execute_reply":"2021-11-28T19:03:16.636496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualisation\nimport matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(classifierHistory.history['accuracy'])\nplt.plot(classifierHistory.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T19:03:31.293010Z","iopub.execute_input":"2021-11-28T19:03:31.293482Z","iopub.status.idle":"2021-11-28T19:03:31.525041Z","shell.execute_reply.started":"2021-11-28T19:03:31.293442Z","shell.execute_reply":"2021-11-28T19:03:31.524298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(classifierHistory.history['loss'])\nplt.plot(classifierHistory.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T19:03:45.720977Z","iopub.execute_input":"2021-11-28T19:03:45.721257Z","iopub.status.idle":"2021-11-28T19:03:45.917782Z","shell.execute_reply.started":"2021-11-28T19:03:45.721211Z","shell.execute_reply":"2021-11-28T19:03:45.917102Z"},"trusted":true},"execution_count":null,"outputs":[]}]}